

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>6.2. 基于局部感受野的极速学习机 &mdash; A tutorial on Artificial Intelligence 0.1 文档</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/favicon1.ico"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../../../_static/proof.css" type="text/css" />
  
    <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" type="text/css" />
  
    <link rel="stylesheet" href="../../../_static/katex-math.css" type="text/css" />
  

  
        <link rel="index" title="索引"
              href="../../../genindex.html"/>
        <link rel="search" title="搜索" href="../../../search.html"/>
    <link rel="top" title="A tutorial on Artificial Intelligence 0.1 文档" href="../../../index.html"/>
        <link rel="up" title="6. 极速学习机" href="index.html"/>
        <link rel="next" title="6.3. 模糊极速学习机" href="FuzzyELM.html"/>
        <link rel="prev" title="6.1. 经典极速学习机" href="ELM.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> A tutorial on Artificial Intelligence
          

          
            
            <img src="../../../_static/logo1.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../Introduction/intro.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../BasisMath/index.html">第一卷 数学基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../BasisPhysics/index.html">第二卷 经典物理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ModernPhysics/index.html">第三卷 现代物理学</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ComputerScience/index.html">第四卷 计算机学</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../SignalProcessing/index.html">第五卷 信号处理</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">第六卷 人工智能</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../intro.html">简介</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Optimization/index.html">优化方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../MachineLearning/index.html">机器学习</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">神经网络</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../intro.html">1. 简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ModulesOfNN/index.html">2. 神经网络组件</a></li>
<li class="toctree-l3"><a class="reference internal" href="../LossFunctions/index.html">3. 神经网络常用损失函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../SimpleNeuralNetwork/index.html">4. 简单神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="../SupportVectorMachine/index.html">5. 支撑矢量机</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="index.html">6. 极速学习机</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="ELM.html">6.1. 经典极速学习机</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">6.2. 基于局部感受野的极速学习机</a></li>
<li class="toctree-l4"><a class="reference internal" href="FuzzyELM.html">6.3. 模糊极速学习机</a></li>
<li class="toctree-l4"><a class="reference internal" href="FuzzyELMLRF.html">6.4. 基于局部感受野的模糊极速学习机</a></li>
<li class="toctree-l4"><a class="reference internal" href="OSELM.html">6.5. 在线极速学习机</a></li>
<li class="toctree-l4"><a class="reference internal" href="OSELMLRF.html">6.6. 基于局部感受野的在线极速学习机</a></li>
<li class="toctree-l4"><a class="reference internal" href="zreference.html">6.7. 参考文献</a></li>
<li class="toctree-l4"><a class="reference internal" href="glossary.html">6.8. 名词术语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../EnergyBasedNeuralNetwork/index.html">7. 基于能量的神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ConvolutionalNeuralNetwork/index.html">8. 卷积神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="../RecursiveNeuralNetwork/index.html">9. 递归神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenerativeNeuralNetwork/index.html">10. 生成式神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ResidualNeuralNetwork/index.html">11. 残差神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="../FractalNeuralNetwork/index.html">12. 分形神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="../StochasticNeuralNetwork/index.html">13. 随机神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ComplexityAnalysis/index.html">14. 复杂度分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zreference.html">15. 参考文献</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glossary.html">16. 名词术语</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../DeepLearning/index.html">深度学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../FuzzySystem/index.html">模糊神经系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../CurriculumLearning/index.html">课程学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../SelfPacedLearning/index.html">自步学习</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../Radar/index.html">第七卷 雷达信号处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Medical/index.html">第八卷 医学信号处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Astronomy/index.html">第九卷 天文学</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Application/index.html">第十卷 应用实践</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Supplement/index.html">第十一卷 补充内容</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../glossary/glossary.html">名词术语</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">A tutorial on Artificial Intelligence</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">第六卷 人工智能</a> &raquo;</li>
        
          <li><a href="../index.html">神经网络</a> &raquo;</li>
        
          <li><a href="index.html"><span class="section-number">6. </span>极速学习机</a> &raquo;</li>
        
      <li><span class="section-number">6.2. </span>基于局部感受野的极速学习机</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="section-extremelearningmachinelocalreceptivefields">
<span id="id1"></span><h1><span class="section-number">6.2. </span>基于局部感受野的极速学习机<a class="headerlink" href="#section-extremelearningmachinelocalreceptivefields" title="永久链接至标题">¶</a></h1>
<div class="section" id="id2">
<h2><span class="section-number">6.2.1. </span>说明<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>本文是”Local Receptive Fields Based Extreme Learning Machine”<a class="footnote-reference brackets" href="#id33" id="id3">1</a> 的学习笔记.</p>
<p>文章主要包含两部分内容, <strong>极速学习机</strong>(也有人译作极限学习机或极端学习机, Extreme Learning Machine, ELM)和<strong>局部感受野</strong>(Local Receptive
Fields, LRF).</p>
<p><strong>极速学习机</strong>( 也有人译作极限学习机或极端学习机, Extreme Learning Machine, ELM )实际上是一种<strong>单隐层前馈神经网络</strong>(Single-hidden Layer
Feedforward Neural networks, SLFNs) <a class="footnote-reference brackets" href="#id34" id="id4">2</a>, 由南洋理工大学黄广斌教授于2004年提出, 请参见<a class="reference external" href="http://www.ntu.edu.sg/home/egbhuang/index.html">主页</a>. ELM可用于特征学习(feature learning), 聚类(clustering), 回归(regression)和分类(classification).</p>
</div>
<div class="section" id="id6">
<h2><span class="section-number">6.2.2. </span>摘要内容<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><p>传统观点：神经网络的隐藏层神经元需要在训练阶段迭代调整.</p></li>
<li><p>ELM理论打破了这种信条, 认为隐层神经元虽然很重要, 但不需要迭代调整.
隐藏层节点的所有参数（权重<span class="math">\(\bm W\)</span>和偏置<span class="math">\(\bm b\)</span>）都独立于训练样例, 可以随机的(任意连续概率分布)生成, 这样的ELM依然具有<strong>普适的逼近和分类能力</strong>( <a class="reference external" href="http://en.wikipedia.org/wiki/Universal_approximation_theorem">universal approximation</a> and classification ).</p></li>
</ul>
<p>文章提出了一种局部连接的ELM的普适结构.</p>
<ol class="arabic simple">
<li><p>在输入层引入局部感受野;</p></li>
<li><p>每个隐层节点可以是几个隐层节点(子网络, sub-network)的组合.</p></li>
</ol>
<p>在NORB数据集上, 与传统的深度神经网络作了对比:</p>
<ul class="simple">
<li><p>将错误率从6.5%降到2.7%</p></li>
<li><p>学习速度快了200倍</p></li>
</ul>
</div>
<div class="section" id="id7">
<h2><span class="section-number">6.2.3. </span>引言部分<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h2>
<p>文中提到, 机器学习的成功依赖于三个关键因素:</p>
<ol class="arabic simple">
<li><p>强大的计算环境(powerful computing environments)</p></li>
<li><p>丰富的动态数据(rich and dynamic data)</p></li>
<li><p>有效的学习算法(efficient learning algorithms)</p></li>
</ol>
<p>传统的诸如BP的训练方法的缺点:</p>
<ul class="simple">
<li><p>大量的梯度下降搜索操作</p></li>
<li><p>慢的收敛速度</p></li>
<li><p>容易陷入局部最优</p></li>
<li><p>密集的人工干预</p></li>
</ul>
<p>ELM克服了这些缺点和限制, 不仅训练时间急剧减少, 学习的精度也非常高.</p>
<p><strong>基于局部感受野的极速学习机</strong>( Local Receptive Fields Based Extreme Learning Machine, ELM-LRF )和卷积神经网络(Convolutional Neural Networks, CNNs)在局部连接上相似, 但有两点不同:</p>
<ol class="arabic simple">
<li><p>局部感受野:
ELM-LRF可以灵活的使用由连续概率分布随机生成的不同形式的局部感受野;
而CNN使用固定的卷积隐层节点作为局部感受野.</p></li>
<li><p>训练: CNN使用BP算法;
而ELM-LRF的输入权重和偏置可以随机生成, 从而输出权重可以解析地计算.</p></li>
</ol>
</div>
<div class="section" id="elm-cnnhtm">
<h2><span class="section-number">6.2.4. </span>回顾ELM, CNN和HTM<a class="headerlink" href="#elm-cnnhtm" title="永久链接至标题">¶</a></h2>
<div class="section" id="id8">
<h3>极速学习机<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h3>
<p>ELM理论 <a class="footnote-reference brackets" href="#id35" id="id9">3</a>  <a class="footnote-reference brackets" href="#id36" id="id10">4</a> <a class="footnote-reference brackets" href="#id37" id="id11">5</a> 表明, 只要隐层神经元的<strong>激活函数</strong>是<strong>非线性分段连续</strong>(nonlinear
piecewise continues)的, 神经网络就不需要通过迭代调整网络来获得学习能力.</p>
<div class="figure align-default" id="id38">
<img alt="图1 ELM的结构" src="../../../_images/20150514171338573.png" />
<p class="caption"><span class="caption-number">图 6.3 </span><span class="caption-text">图1 ELM的结构</span><a class="headerlink" href="#id38" title="永久链接至图片">¶</a></p>
</div>
<p>如上图所示, ELM包含两步: <strong>特征映射</strong>和<strong>特征学习</strong>.</p>
<div class="section" id="elm">
<h4>ELM特征映射<a class="headerlink" href="#elm" title="永久链接至标题">¶</a></h4>
<p>ELM的输出函数(output function):</p>
<div class="math">
\[f({\bm x}) = \sum_{i=1}^{L}{\bm \beta}_i h_i({\bm x}) = {\bm h}({\bm x}){\bm \beta}

\]</div>
<p>其中, <span class="math">\({\bm \beta}_{L\times{m}} =[{\bm \beta}_1, \cdots, {\bm{ \beta}}_L]^T , \; ({\bm \beta}_i = [\beta_{i1}, \cdots, \beta_{im}]^T)\)</span>是隐层与输出层间的输出权重矩阵, <span class="math">\({\bm h}({\bm x}) = [h_1({\bm x}), \cdots, h_L({\bm x})]\)</span>是隐层的输出向量.</p>
<div class="math">
\[h_i({\bm{x}}) = G({\bm a}_i, b_i, {\bm x}), {\bm a}_i \in {\mathbb R}^d, b_i \in R

\]</div>
<p>其中,  <span class="math">\(G({\bm a}_i, b_i, {\bm x})\)</span>是一个非线性分段连续函数.</p>
<p><span class="math">\({\bm{h}}({\bm{x}})\)</span>实际上是将<span class="math">\(d\)</span>维的输入空间映射到<span class="math">\(L\)</span>维的隐层随机特征空间, 所以<span class="math">\({\bm{h}}({\bm{x}})\)</span>是一个随机特征映射 (feature mapping).</p>
</div>
<div class="section" id="id12">
<h4>ELM特征学习<a class="headerlink" href="#id12" title="永久链接至标题">¶</a></h4>
<p>ELM与传统的学习算法不同, 隐层神经元无需调整, 而且可以得到最小化训练误差和具有最小范数的解：</p>
<div class="math">
\[{\rm min}: ||{\boldsymbol \beta}||_p^{\sigma_1} + C||{\bm H \boldsymbol\beta-T}||_q^{\sigma_2}

\]</div>
<p>其中, <span class="math">\(\sigma_1&gt;0, \sigma_2&gt;0, \quad p,q&gt;0\)</span>,
<span class="math">\(C\)</span>用于控制两项的重要性.</p>
<p>对于给定的训练集<span class="math">\(({\bm x}_i, {\bm t}_i), i=1, 2, \cdots, N\)</span>, 用<span class="math">\(\bm H\)</span>表示隐藏层输出矩阵:</p>
<div class="math">
\[{\bm H}=\begin{bmatrix} {\bm h}({\bm x}_1)\\ \vdots \\{\bm h}({\bm x}_N)\end{bmatrix} = \begin{bmatrix} h_1({\bm x}_1) & \cdots & h_L({\bm x}_1)\\ \vdots & \vdots & \vdots \\ h_1({\bm x}_N) & \cdots & h_L({\bm x}_N)\end{bmatrix}

\]</div>
<p><span class="math">\(\bm T\)</span>是训练样例的目标矩阵（target matrix, 由类标构成）：</p>
<div class="math">
\[{\bm T}=\begin{bmatrix} {\bm t}_1^T\\ \vdots \\{\bm t}_N^T\end{bmatrix} = \begin{bmatrix} t_{11} & \cdots & t_{1m}\\ \vdots & \vdots & \vdots \\ t_{N1} & \cdots & t_{Nm} \end{bmatrix}

\]</div>
<p>有很多种方法可以计算权重<span class="math">\(\boldsymbol \beta\)</span>, 如正交投影的方法、迭代的方法、和奇异值分解等等.</p>
<p>当<span class="math">\(\sigma_1= \sigma_2= p=q=2\)</span>时, 常用的闭式解（closed-form）为：</p>
<div class="math">
\[{\boldsymbol \beta}=\begin{cases}{{\bm H}^T({{\bm I}\over C}+{\bm{HH}}^T)^{-1}{\bm T}}, & {\rm if}\   N\le L \\ {({{\bm I}\over C}+{\bm H}^T{\bm H})^{-1}{\bm H}^T{\bm T}}, & {\rm if}\   N\ge L \end{cases}

\]</div>
<p><strong>定理1</strong>：普适近似能力：设激活函数为任意非常数分段连续函数（nonconstant
piecewise continuous
function）, 如果通过调整隐层神经元的参数可以使SLFNs近似任意目标函数<span class="math">\(f({\bm x})\)</span>, 那么可以按照任意连续概率分布函数随机生成序列<span class="math">\(\{h_i({\bm x})\}_{i=1}^L\)</span>, 能够找到适当的<span class="math">\({\boldsymbol \beta}\)</span>, 使得极限<span class="math">\(\lim_{L\to \infty} ||{\boldsymbol \beta}_i h_i({\bm x})-f({\bm x})||=0\)</span>依概率收敛于1.</p>
<p><strong>定理2</strong>：分类能力：设激活函数为任意非常数分段连续函数, 如果通过调整隐层神经元的参数可以使SLFNs近似任意目标函数<span class="math">\(f({\bm x})\)</span>, 那么带有随机映射<span class="math">\(h({\bm x})\)</span>的SLFNs可以分离任何形状的任意不相交（disjoint）区域.</p>
</div>
</div>
<div class="section" id="id13">
<h3>卷积神经网络<a class="headerlink" href="#id13" title="永久链接至标题">¶</a></h3>
<p>卷积神经网络（Convolutional Neural Network, CNN）是多层前馈神经网络（Multi-Layer Feedforward Neural Network, 也叫多层感知器, MLPs）的变种.</p>
<p>CNN受启发与人类的视觉皮层, 输入至隐藏层采用局部连接.</p>
<p>这是全连接神经网络和局部连接神经网络示意图：
<img alt="全连接神经网络与局部连接神经网络" src="../../../_images/20150519204332631.png" /></p>
<p>这是局部连接神经网络与卷积神经网络示意图：
<img alt="局部连接神经网络与卷积神经网络" src="../../../_images/20150519204520505.png" /></p>
<p>下图是卷积神经网络结构示意图： <img alt="卷积神经网络结构示意图" src="../../../_images/20150519205126212.png" /></p>
<p>CNN包含两个基本操作：<strong>卷积</strong>（convolution）和<strong>池化</strong>（pooling）, 通常交替排列卷积层和池化层直至获得高级的特征. 上图中的“Subsampling”其实就是池化操作.</p>
<p>卷积神经网络特点</p>
<ul class="simple">
<li><p>局部连接（网络参数数目减小）</p></li>
<li><p>权值共享</p></li>
<li><p>采用BP训练（包含BP的弊病）</p></li>
<li><p>运算量大</p></li>
</ul>
<div class="section" id="id14">
<h4>卷积<a class="headerlink" href="#id14" title="永久链接至标题">¶</a></h4>
<p>对于一个卷积层, 用<span class="math">\(\gamma\)</span>表示该卷积层的值, 用<span class="math">\(x\)</span>表示其前一层的值, 假设该卷积层前一层的大小是<span class="math">\(d\times d\)</span>, <strong>感受野</strong>（receptive
field）的大小是<span class="math">\(r\times r\)</span>, 则</p>
<div class="math">
\[\gamma_{i,j}=g(\sum_{m=1}^r \sum_{n=1}^r{x_{i+m-1,\ j+n-1}}\cdot w_{m,\ n}+b), \quad i,j=1,\cdots, (d-r+1)

\]</div>
</div>
<div class="section" id="id15">
<h4>池化<a class="headerlink" href="#id15" title="永久链接至标题">¶</a></h4>
<p>为减少特征的维数并引入平移不变性, 在局部区域引入池化操作, 通常有平均池化和最大池化.</p>
<ul class="simple">
<li><p>平均池化使得提取的特征对微小变形鲁棒, 与视觉感知中的复杂细胞功能类似.</p></li>
<li><p>最大池化使得提取的特征具有平移不变性.</p></li>
<li><p>池化区域通常是不重叠的.</p></li>
</ul>
</div>
</div>
<div class="section" id="id16">
<h3>层级实时记忆<a class="headerlink" href="#id16" title="永久链接至标题">¶</a></h3>
<p>层级实时记忆 (<a class="reference external" href="http://en.wikipedia.org/wiki/Hierarchical_temporal_memory">Hierarchical Temporal Memory</a> , HTM)
是一个在线式机器学习模型 (an online machine learning model)
, 它能发现和推断出观测输入模式或序列的高层次原因.
HTM组合和扩展了贝叶斯网络、空时聚类算法中的方法, 同时利用了神经网络中常用的节点的树形层次结构.</p>
<div class="figure align-default" id="id39">
<img alt="层级实时记忆（HTM）网络结构" src="../../../_images/20150519221917898.png" />
<p class="caption"><span class="caption-number">图 6.4 </span><span class="caption-text">层级实时记忆（HTM）网络结构</span><a class="headerlink" href="#id39" title="永久链接至图片">¶</a></p>
</div>
</div>
</div>
<div class="section" id="elm-lrf">
<h2><span class="section-number">6.2.5. </span>ELM-LRF 原理<a class="headerlink" href="#elm-lrf" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><p>输入与隐藏层间的连接是稀疏的, 且由相应的局部感受野（对连续概率分布采样得到）包围.</p></li>
<li><p>组合节点：通过把几个隐藏层节点组合在一起, 引入平移不变性. （translational
invariance）.</p></li>
</ul>
<div class="section" id="a-full-and-local-connections">
<h3>A. 全连接与局部连接（Full and Local Connections）<a class="headerlink" href="#a-full-and-local-connections" title="永久链接至标题">¶</a></h3>
<p>ELM理论证明, 隐藏层节点可以按照任意概率分布生成, 这里的随机是指：</p>
<ul class="simple">
<li><p>输入与隐藏层节点间的连接密度是根据不同类型的概率分布随机采样得到的.</p></li>
<li><p>输入与隐藏层节点间的连接权重也是随机生成的.</p></li>
</ul>
<p>如下图所示, （a）图为隐藏层节点全连接的形式, 相关的应用研究很多, 且ELM在诸如遥感、时间序列分析、文本分类、行为识别等应用领域取得了最高水平的性能.</p>
<div class="figure align-default" id="id40">
<img alt="图6 全连接与局部连接" src="../../../_images/20150604111247665.png" />
<p class="caption"><span class="caption-number">图 6.5 </span><span class="caption-text">图6 全连接与局部连接</span><a class="headerlink" href="#id40" title="永久链接至图片">¶</a></p>
</div>
<p>然而, 上面的工作仅关注于权重的随机, 忽略了连接也可以随机的属性. 自然图像和语言的强的局部关系, 使得全连接很不适合.</p>
</div>
<div class="section" id="b-elm">
<h3>B. 基于局部感受野的ELM<a class="headerlink" href="#b-elm" title="永久链接至标题">¶</a></h3>
<p>如上图中（b）图所示, 输入层与一个隐藏层节点<span class="math">\(i\)</span>间的连接是根据连续概率分布随机生成的, 这种随机的连接也就构成了局部感受野.</p>
<p>当ELM-LRF应用于图像处理等相似任务时, 它学习图像的局部结构并在隐藏层生成更为有意义的表示.</p>
</div>
<div class="section" id="c">
<h3>C. 组合节点<a class="headerlink" href="#c" title="永久链接至标题">¶</a></h3>
<p>ELM理论表明, ELM中的一个隐层节点可以是几个隐层节点的组合, 或者是节点构成的子网络. 如下图7所示, 组合节点<span class="math">\(i\)</span>由一个子网络形成, 这个子网络的输出实际上是对应于3个局部感受野的3个隐藏层节点的和.</p>
<div class="figure align-default" id="id41">
<img alt="图7 ELM的组合节点" src="../../../_images/20150604113758956.png" />
<p class="caption"><span class="caption-number">图 6.6 </span><span class="caption-text">图7 ELM的组合节点</span><a class="headerlink" href="#id41" title="永久链接至图片">¶</a></p>
</div>
<p>实际上, 组合节点完成了池化的功能：</p>
<ul class="simple">
<li><p>在一个节点生成的特征在不同的节点也有用.</p></li>
<li><p>ELM-LRF网络具有平移和旋转不变性.</p></li>
<li><p>输入与组合节点间的连接能更好的学习局部特征.</p></li>
</ul>
</div>
</div>
<div class="section" id="id17">
<h2><span class="section-number">6.2.6. </span>局部感受野的实现<a class="headerlink" href="#id17" title="永久链接至标题">¶</a></h2>
<div class="section" id="a-elm-lrf">
<h3>A. ELM-LRF的特殊组合节点<a class="headerlink" href="#a-elm-lrf" title="永久链接至标题">¶</a></h3>
<p>尽管ELM中可以使用各种不同的局部感受野和组合节点, 为了方便实现, 文章中采用特殊的局部感受野和组合节点如下图：</p>
<div class="figure align-default" id="id42">
<img alt="图8 文中实现的ELM-LRF结构" src="../../../_images/20150604120129956.png" />
<p class="caption"><span class="caption-number">图 6.7 </span><span class="caption-text">图8 文中实现的ELM-LRF结构</span><a class="headerlink" href="#id42" title="永久链接至图片">¶</a></p>
</div>
<ul class="simple">
<li><p>采样分布：采用简单的阶梯概率函数（Simple Step Probability
Function）；</p></li>
<li><p>组合节点：平方根池化（square/square-root pooling）结构；</p></li>
<li><p>局部感受野：每个隐层节点的局部感受野由距中心一定距离内的输入节点组成；</p></li>
<li><p>卷积操作：对于不同隐藏层节点, 共享输入权重实现卷积操作.</p></li>
</ul>
</div>
<div class="section" id="b">
<h3>B. 随机输入权重<a class="headerlink" href="#b" title="永久链接至标题">¶</a></h3>
<p>为了获得输入的充分表示（thorough
representations）, 采用<span class="math">\(K\)</span>个不同的输入权重, 从而得到<span class="math">\(K\)</span>个互异的特征图：</p>
<div class="figure align-default" id="id43">
<img alt="带有K个特征图的ELM-LRF网络的实现" src="../../../_images/20150604121233292.png" />
<p class="caption"><span class="caption-number">图 6.8 </span><span class="caption-text">带有K个特征图的ELM-LRF网络的实现</span><a class="headerlink" href="#id43" title="永久链接至图片">¶</a></p>
</div>
<p>其中,</p>
<ul class="simple">
<li><p>隐藏层由随机卷积节点组成；</p></li>
<li><p>同一特征图（Feature Map）共享同一输入权重, 不同特征图输入权重不同；</p></li>
<li><p>输入权重随机生成并正交化, 正交化的输入权重可以提取更为完备的特征.</p></li>
</ul>
<p>输入权重的生成与正交化操作：</p>
<ol class="arabic simple">
<li><p>随机生成初始权重<span class="math">\(\hat{\bm{A}}^{\rm init}\)</span>. 设输入大小为<span class="math">\(d\times d\)</span>, 感受野大小为<span class="math">\(r\times r\)</span>, 那么特征图的大小为<span class="math">\((d-r+1)\times(d-r+1)\)</span>. 注：文章采用标准高斯分布, 且不包含偏置, 因为它不需要.</p></li>
</ol>
<div class="math">
\[{\widehat {\bm{A}}^{init}} \in {{\mathbb{R}}^{{r^2} \times K}},\;\;{\widehat {\bm{A}}^{init}} = [\widehat {\bm{a}}_1^{init},\widehat {\bm{a}}_2^{init}, \cdots ,\widehat {\bm{a}}_K^{init}],\;\;\widehat {\bm{a}}_k^{init} \in {{\mathbb{R}}^{{r^2}}},\;k = 1, \cdots ,K

\]</div>
<ol class="arabic simple" start="2">
<li><p>正交化初始权重<span class="math">\(\hat{\bm{A}}^{\rm init}\)</span>. 采用奇异值分解（SVD）正交化, 正交化的初始权重记为<span class="math">\(\hat{\bm A}\)</span>, 它的每一列<span class="math">\(\hat{\bm a}_k\)</span>都是<span class="math">\(\hat{\bm{A}}^{\rm init}\)</span>的正交基. 注意, 当<span class="math">\(r^2&lt;K\)</span>时, 先转置, 再正交化, 然后转置回来.</p></li>
</ol>
<p>第<span class="math">\(k\)</span>个特征图的输入权重是<span class="math">\({\bm a}_k \in {\mathbb R}^{r\times r}\)</span>, 由<span class="math">\(\hat{\bm a}_k\)</span>逐列排成. 第<span class="math">\(k\)</span>个特征图的卷积节点<span class="math">\((i,j)\)</span>的值<span class="math">\(c_{i,j,k}\)</span>由下式计算：</p>
<div class="math" id="equation-equ-convfeature">
<span class="eqno">(6.1)<a class="headerlink" href="#equation-equ-convfeature" title="公式的永久链接">¶</a></span>\[c_{i,j,k}({\bm x})=\sum_{m=1}^r\sum_{n=1}^r(x_{i+m-1,\ j+n-1}\cdot a_{m,n,k}), \ \  i,j=1,\cdots, (d-r+1)

\]</div>
</div>
<div class="section" id="c-square-square-root-pooling">
<h3>C. 平方根池化（square/square-root pooling）结构<a class="headerlink" href="#c-square-square-root-pooling" title="永久链接至标题">¶</a></h3>
<p>池化大小<span class="math">\(e\)</span>表示池化中心到边的距离, 且池化图（pooling
map）与特征图大小相同（<span class="math">\((d-r+1)\times(d-r+1)\)</span>）. <span class="math">\(c_{i,j,k}\)</span>和<span class="math">\(h_{p,q,k}\)</span>, 分别表示第<span class="math">\(k\)</span>个特征图中的节点<span class="math">\((i,j)\)</span>和第<span class="math">\(k\)</span>个池化图中的组合节点<span class="math">\((p,q)\)</span>.</p>
<div class="math" id="equation-equ-poolfeature">
<span class="eqno">(6.2)<a class="headerlink" href="#equation-equ-poolfeature" title="公式的永久链接">¶</a></span>\[h_{p,q,k}=\sqrt{\sum_{i=p-e}^{p+e}\sum_{j=q-e}^{q+e}c_{i,j,k}^2},\quad p,q=1,\cdots,(d-r+1) \\
{\rm{if\ (i,j)\ is\ out\ of\ bound,\ then\ }} c_{i,j,k}=0.

\]</div>
<ul class="simple">
<li><p>平方与求和操作：网络引入非线性校正（rectification
nonlinearity）和平移不变性（translation invariance）的特性；</p></li>
<li><p>卷积操作后紧跟平方/平方根池化结构：使网络具有频率选择性（frequency
selective）和平移不变性（translation invariance）；</p></li>
<li><p>因而非常适合于图像处理.</p></li>
</ul>
</div>
<div class="section" id="d">
<h3>D. 基于输出权重的闭式解<a class="headerlink" href="#d" title="永久链接至标题">¶</a></h3>
<p>池化层与输出层全连接, 输出权重<span class="math">\(\bm{\beta}\)</span>, 采用正则化最小二乘（Regularized
Least-Squares）法解析地计算.</p>
<p>对于每一个输入样例<span class="math">\(\bm x\)</span>, 使用 <a class="reference internal" href="#equation-equ-convfeature">式.6.1</a> 计算特征图的值, 然后使用 <a class="reference internal" href="#equation-equ-poolfeature">式.6.2</a> 计算池化图（即组合层）的值. <strong>简单地连接所有组合节点的值形成一个行向量</strong>, 并把<span class="math">\(N\)</span>个输入样例的行向量放在一起, 得到组合层矩阵<span class="math">\({\bm H}\in {\mathbb R}^{N\times K \cdot (d-r+1)^2}\)</span>, 输出权重矩阵计算为:</p>
<ol class="arabic">
<li><p>if <span class="math">\(N\le K\cdot (d-r+1)^2\)</span></p>
<div class="math">
\[\bm{\beta}={\bm H}^T({{\bm I}\over{C}}+{\bm H}{\bm H}^T)^{-1}{\bm T}

\]</div>
</li>
<li><p>if <span class="math">\(N &gt; K\cdot (d-r+1)^2\)</span></p>
<div class="math">
\[\bm{\beta}=({{\bm I}\over{C}}+{\bm H}^T{\bm H})^{-1}{\bm H}^T{\bm T}

\]</div>
</li>
</ol>
</div>
</div>
<div class="section" id="id18">
<h2><span class="section-number">6.2.7. </span>讨论<a class="headerlink" href="#id18" title="永久链接至标题">¶</a></h2>
<div class="section" id="a">
<h3>A. 普适近似和分类能力<a class="headerlink" href="#a" title="永久链接至标题">¶</a></h3>
<ol class="arabic simple">
<li><p>输入与隐藏层节点间的连接, 是根据不同类型的连续概率分布随机采样构建的, 这样的网络依然具有普适近似能力和分类能力.</p></li>
<li><p>输入与隐藏层节点间没有连接的, 可以认为连接权重不重要以至于可以忽略, 因而仍然可以认为分布函数是连续的, 可以保持网络的普适近似与分类能力.</p></li>
<li><p>ELM中的隐藏层节点可以是不同节点的线性或非线性组合.</p></li>
</ol>
<p>由于隐藏层节点的激活函数是非线性分段连续的, 所以第<span class="math">\(k\)</span>个池化图<span class="math">\(h_{p,q,k}\)</span>中的组合节点<span class="math">\((p,q)\)</span>, 仍然可以表示成ELM隐层节点的基本形式：</p>
<div class="math">
\[h_{p,q,k}=G({\bm a}_{p,q},{b}_{p,q},{\bm x}), \ p,q=1,\cdots,(d-r+1)

\]</div>
<p>在平方根池化结构中, <span class="math">\(G\)</span>显然是非线性分段连续的, 所以ELM-LRF仍然保留了普适近似与分类能力, 从而可以学习输入数据更为复杂的特征.</p>
</div>
<div class="section" id="b-elm-lrfhtmcnn">
<h3>B. ELM-LRF与HTM和CNN的关系<a class="headerlink" href="#b-elm-lrfhtmcnn" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li><p>ELM-LRF与HTM：在通过构造一层一层的学习模式, 来模拟大脑处理逐渐复杂的输入形式上是相似的；然而, ELM-LRF更为有效, 因为ELM-LRF网络的连接和输入权重都是随机生成的, 而HTM需要仔细设计网络和调整参数.</p></li>
<li><p>ELM-LRF与CNN：它们都直接处理原始输入, 并利用局部连接来限制网络学习诸如自然图像和语言中的空间相关性. 它们的不同是：</p></li>
</ul>
<ol class="arabic simple">
<li><p>局部感受野：ELM-LRF更为灵活和宽泛, 可以根据不同类型的概率分布随机采样生成, 而CNN只使用卷积隐藏层节点；尽管本文仅使用随机卷积节点作为ELM-LRF的特殊的局部感受野, 研究其它类型的感受野也是很有价值的.</p></li>
<li><p>训练：CNN中的隐藏层节点需要调整, 而通常采用BP算法, 这使得CNN面临BP中的琐碎问题, 如：局部最优, 慢的收敛速度. 而ELM-LRF随机生成输入权重并解析地计算输出权重. 也就是计算主要是输出权重的计算, 从而ELM-LRF更为高效.</p></li>
</ol>
</div>
</div>
<div class="section" id="id19">
<h2><span class="section-number">6.2.8. </span>实验<a class="headerlink" href="#id19" title="永久链接至标题">¶</a></h2>
<ol class="arabic simple">
<li><p>实验数据 ELM-LRF与Deep
Learning的方法进行了对比, 数据集选择目标识别数据集：NORB. NORB包含24300幅<strong>训练</strong>用立体图像（stereo
image）和24300幅<strong>测试</strong>用立体图像, 每个都有5类并且很多都进行了3D和光照处理. 下图是NORB数据集中的60个样例, 每个样本有两幅图, 物体尺寸是归一化的, 背景也是一致的. 文中进行了下采样到<span class="math">\(32\times 32\)</span>的操作.
<img alt="图10 NORB中的60个样例" src="../../../_images/20150604173627035.png" /></p></li>
<li><p>实验平台与参数 实验平台：MATLAB2013a, Intel Xeon E5-2650, 2GHz
GPU, 256GB RAM.
参数：感受野大小<span class="math">\(\{4\times 4,6\times 6\}\)</span>；特征图的数量<span class="math">\(\{24,36,48,60\}\)</span>；池化大小<span class="math">\({1,2,3,4}\)</span>；<span class="math">\(C\)</span>
的值<span class="math">\(\{0.01,0.1,1,10,100\}\)</span>, 采用5倍交叉验证, 来选择参数, 最优参数如 <a class="reference internal" href="#table-optimalparameterselmlrf"><span class="std std-numref">表 6.1</span></a> 所示.</p></li>
</ol>
<table class="docutils align-default" id="table-optimalparameterselmlrf">
<caption><span class="caption-number">表 6.1 </span><span class="caption-text">ELMLRF的最优参数</span><a class="headerlink" href="#table-optimalparameterselmlrf" title="永久链接至表格">¶</a></caption>
<colgroup>
<col style="width: 7%" />
<col style="width: 15%" />
<col style="width: 14%" />
<col style="width: 21%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 10%" />
<col style="width: 4%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>DATASET</p></th>
<th class="head"><p># OF TRAINING DATA</p></th>
<th class="head"><p># OF TESTING DATA</p></th>
<th class="head"><p>INPUT DIMENSIONS</p></th>
<th class="head"><p>RECEPTIVE FIELD</p></th>
<th class="head"><p># OF FEATURE MAPS</p></th>
<th class="head"><p>POOLING SIZE</p></th>
<th class="head"><p>C</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>NORB</p></td>
<td><p>24300</p></td>
<td><p>24300</p></td>
<td><p><span class="math">\(32\times 32\times 2\)</span></p></td>
<td><p><span class="math">\(4\times 4\)</span></p></td>
<td><p>48</p></td>
<td><p>3</p></td>
<td><p>0.01</p></td>
</tr>
</tbody>
</table>
<div class="section" id="id20">
<h3>A. 测试误差<a class="headerlink" href="#id20" title="永久链接至标题">¶</a></h3>
<p>如  <a class="reference internal" href="#table-testerrordiffmethodsonnorb"><span class="std std-numref">表 6.2</span></a> 所示, ELM-LRF要比其它微调的算法的精度更高, 而且耗时少. 与CNN和DBN的方法相比, ELM-LRF将错误率从<span class="math">\(6.5\%\)</span>降到<span class="math">\(2.74\%\)</span>.</p>
<table class="docutils align-default" id="table-testerrordiffmethodsonnorb">
<caption><span class="caption-number">表 6.2 </span><span class="caption-text">不同算法在NORB数据集上的测试误差</span><a class="headerlink" href="#table-testerrordiffmethodsonnorb" title="永久链接至表格">¶</a></caption>
<colgroup>
<col style="width: 4%" />
<col style="width: 71%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>ALGORITHMS </p></th>
<th class="head"><p>TEST ERROR RATES </p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p></p></td>
<td><p>ELM-LRF </p></td>
<td><p>2.74% </p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>ELM-LRF (NO ORTHOGONALIZATION) </p></td>
<td><p>4.01% </p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>RANDOM WEIGHTS (ELM FEATURE MAPPING + SVM CLASSIFIER) </p></td>
<td><p>4.8% </p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>K-MEANS + SOFT ACTIVATION </p></td>
<td><p>2.8% </p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>TILED CNN </p></td>
<td><p>3.9% </p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>CNN </p></td>
<td><p>6.6% </p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>DBN </p></td>
<td><p>6.5% </p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id21">
<h3>B. 训练时间<a class="headerlink" href="#id21" title="永久链接至标题">¶</a></h3>
<p>公平起见, 其它的算法也运行在本实验平台, 如 <a class="reference internal" href="#table-speeddiffmethodsonnorb"><span class="std std-numref">表 6.3</span></a> 所示, ELM-LRF学习速度比其它算法快至200倍.</p>
<table class="docutils align-default" id="table-speeddiffmethodsonnorb">
<caption><span class="caption-number">表 6.3 </span><span class="caption-text">不同算法在NORB数据集上的测试速度</span><a class="headerlink" href="#table-speeddiffmethodsonnorb" title="永久链接至表格">¶</a></caption>
<colgroup>
<col style="width: 3%" />
<col style="width: 59%" />
<col style="width: 20%" />
<col style="width: 18%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>ALGORITHMS </p></th>
<th class="head"><p>TRAINING TIM(s) </p></th>
<th class="head"><p>SPEEDUP TIMES </p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p></p></td>
<td><p>ELM-LRF  </p></td>
<td><p>394.16      </p></td>
<td><p>217.47        </p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>ELM-LRF (NO ORTHOGONALIZATION) </p></td>
<td><p>391.89 </p></td>
<td><p>218.73 </p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>RANDOM WEIGHTS (ELM FEATURE MAPPING + SVM CLASSIFIER) </p></td>
<td><p>1764.28 </p></td>
<td><p>48.58 </p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>K-MEANS + SOFT ACTIVATION </p></td>
<td><p>6920.47 </p></td>
<td><p>12.39 </p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>TILED CNN </p></td>
<td><p>15104.55 </p></td>
<td><p>5.67 </p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>CNN5 </p></td>
<td><p>53378.16 </p></td>
<td><p>1.61 </p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>DBN </p></td>
<td><p>85717.14 </p></td>
<td><p>1 </p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id22">
<h3>C. 特征图<a class="headerlink" href="#id22" title="永久链接至标题">¶</a></h3>
<p>下图显示了一个样本的48个特征图. 可以看出, 这些特征图的轮廓线相似的, 这是由于它们来自同一幅输入图像. 然而每个图都有自己明显突出的部分, 这就获得了原始图像的互异表示, 就原始图像的不同抽象, 使得分类变得容易和准确.</p>
<div class="figure align-default" id="id44">
<img alt="图11 一个样例：（a）原始图像；（b）48个特征图" src="../../../_images/20150604180220430.png" />
<p class="caption"><span class="caption-number">图 6.9 </span><span class="caption-text">图11 一个样例：（a）原始图像；（b）48个特征图</span><a class="headerlink" href="#id44" title="永久链接至图片">¶</a></p>
</div>
</div>
<div class="section" id="id23">
<h3>D. 随机输入权重的正交化<a class="headerlink" href="#id23" title="永久链接至标题">¶</a></h3>
<p>实验中也分析了随机输入权重的正交化的贡献. 以48个特征图中的卷积节点中心的值为例, <code class="xref std std-numref docutils literal notranslate"><span class="pre">fig-RandomWeightsOrthogonalizationELMLRF</span></code> 显示了48个特征图中, 中心卷积节点的值在对输入权重正交化前后的变化分布.</p>
<p>由 <code class="xref std std-numref docutils literal notranslate"><span class="pre">fig-RandomWeightsOrthogonalizationELMLRF</span></code> 可以看出, 正交的随机权重的分布更均匀, 特征图中的其它位置的卷积节点也是如此. 所以正交化使得物体更加线性独立和易分类的. 不过, 即使不正交化, 仍能获得<span class="math">\(4.01\%\)</span>的测试误差与传统方法相比, 减少了<span class="math">\(38\%\)</span>.</p>
</div>
</div>
<div class="section" id="id24">
<h2><span class="section-number">6.2.9. </span>结论<a class="headerlink" href="#id24" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><p>ELM中引入局部感受野来学习局部结构；</p></li>
<li><p>组合节点的引入使网络具有平移不变性；</p></li>
<li><p>输入权重随机生成, 然后进行正交化, 这样可以提取更为完备的特征；</p></li>
<li><p>输出权重可以解析地计算, 计算复杂度低；</p></li>
<li><p>局部感受野的形式多样；</p></li>
<li><p>随机卷积节点可以作为ELM的一个有效的局部感受野实现方法；</p></li>
<li><p>实验表明, 无论在精度上还是学习速度上, ELM-LRF都远优于传统的深度学习方法.</p></li>
</ul>
<p>进一步的工作：</p>
<ol class="arabic simple">
<li><p>ELM的不同类型的局部感受野的影响；</p></li>
<li><p>ELM的不同卷积节点的影响；</p></li>
<li><p>堆栈式ELM-LRF, 可以通过在前一组合层后采用局部连接来堆叠ELM-LRF.</p></li>
</ol>
</div>
<div class="section" id="id25">
<h2><span class="section-number">6.2.10. </span>代码实现<a class="headerlink" href="#id25" title="永久链接至标题">¶</a></h2>
<div class="section" id="source-code">
<h3>Source Code<a class="headerlink" href="#source-code" title="永久链接至标题">¶</a></h3>
<p>By Me：<a class="reference external" href="https://github.com/antsfamily/ELM-LRF">https://github.com/antsfamily/ELM-LRF</a></p>
<p>Another：<a class="reference external" href="https://github.com/ExtremeLearningMachines/ELM-LRF">https://github.com/ExtremeLearningMachines/ELM-LRF</a></p>
</div>
<div class="section" id="experimental-results">
<h3>Experimental Results<a class="headerlink" href="#experimental-results" title="永久链接至标题">¶</a></h3>
<div class="section" id="mnist">
<h4>MNIST数据集<a class="headerlink" href="#mnist" title="永久链接至标题">¶</a></h4>
<ol class="arabic simple">
<li><p>数据集：MNIST, 28*28, uint8, 60K训练, 10K测试</p></li>
<li><p>硬件：Intel i5-3210M 2.5GHz 双核四线程（实验中只用单线程）</p></li>
<li><p>软件：MATLAB</p></li>
<li><p>参数： C = [0.001 0.01 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1];
卷积核：<span class="math">\(5\times5\)</span>, 特征图个数：10, 池化窗口<span class="math">\(3\times3\)</span>.</p></li>
</ol>
<p>注：由于笔记本内存仅有4G, Matlab无法开出:math:<a href="#id26"><span class="problematic" id="id27">`</span></a>60K times 60K <a href="#id28"><span class="problematic" id="id29">`</span></a>的矩阵, 仅用前10K个作为训练.</p>
<p>结果如下：</p>
<div class="highlight-matlab notranslate"><div class="highlight"><pre><span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.001000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.030900</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">95.156250</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.035800</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">16.250000</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.010000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.014400</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">94.109375</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.031900</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">14.859375</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.100000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.005000</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">93.234375</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.031700</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">14.750000</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.200000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.003200</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">92.484375</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.032500</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">15.000000</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.300000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.002500</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">92.718750</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.033700</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">14.953125</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.400000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.002400</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">93.937500</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.034500</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">14.578125</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.500000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.002200</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">91.828125</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.035000</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">14.828125</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.600000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.002100</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">93.453125</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.035400</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">14.781250</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.700000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.001900</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">92.218750</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.035800</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">14.625000</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.800000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.001700</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">93.531250</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.036500</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">16.421875</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.900000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.001500</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">93.343750</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.037100</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">15.359375</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">1.000000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.001400</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">95.015625</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.037500</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">15.109375</span><span class="n">s</span>
</pre></div>
</div>
<p>哈哈, 效果不错！</p>
</div>
<div class="section" id="norb">
<h4>NORB数据集<a class="headerlink" href="#norb" title="永久链接至标题">¶</a></h4>
<p><strong>2016年3月11日补充：</strong></p>
<p>一个月前升级了内存条, 今天又看到有国外童鞋Email问我文章中是如何处理对待NORB数据集的, 它是个双通道的, 即<span class="math">\(32\times 32\times 2 \times 24300\)</span>, 这个文中没有细说, 我之前实现的代码也只是单通道的, 所以今天又重新看了一下, 并更新了代码, 在<a class="reference external" href="https://github.com/antsfamily/ELM-LRF">这里</a>下载.</p>
<div class="section" id="id30">
<h5>论文中代码结果<a class="headerlink" href="#id30" title="永久链接至标题">¶</a></h5>
<p>先看看https://github.com/ExtremeLearningMachines/ELM-LRF代码（这个应该是文章用的）实验结果. 里面的代码给了两组参数, 第一组参数（load
param1）与第二组参数（load
param5）中感受野（或卷积核）大小均为<span class="math">\(4\times 4\)</span>, 池化大小为<span class="math">\(3\times3\)</span>, <span class="math">\(C=0.01\)</span>不同的是特征图的数量, 第一组为<span class="math">\(1\)</span>, 第二组为<span class="math">\(48\)</span>. 第一组结果如下, 第二组根本不能跑, 内存升级到10G还是不行.</p>
<p><strong>第一组参数运行结果（特征图数1）：</strong></p>
<div class="highlight-matlab notranslate"><div class="highlight"><pre><span class="n">train_accuracy</span> <span class="p">=</span>

    <span class="mf">0.7687</span>

<span class="n">The</span> <span class="n">testing</span> <span class="n">begins</span><span class="p">:</span>

<span class="n">test_accuracy</span> <span class="p">=</span>

    <span class="mf">0.6575</span>


<span class="nb">ans</span> <span class="p">=</span>

                  <span class="n">train_time</span><span class="p">:</span> <span class="mf">0.7885</span>
                   <span class="n">test_time</span><span class="p">:</span> <span class="mf">0.0338</span>
              <span class="n">train_accuracy</span><span class="p">:</span> <span class="mf">0.7687</span>
               <span class="n">test_accuracy</span><span class="p">:</span> <span class="mf">0.6575</span>
                <span class="n">time_network</span><span class="p">:</span> <span class="mf">3.8226</span>
    <span class="n">time_transform_test_data</span><span class="p">:</span> <span class="mf">3.4379</span>
</pre></div>
</div>
<p>第一组参数运行结果（特征图数3）：</p>
<div class="highlight-matlab notranslate"><div class="highlight"><pre><span class="n">train_accuracy</span> <span class="p">=</span>

    <span class="mf">0.9627</span>

<span class="n">The</span> <span class="n">testing</span> <span class="n">begins</span><span class="p">:</span>

<span class="n">test_accuracy</span> <span class="p">=</span>

    <span class="mf">0.8342</span>


<span class="nb">ans</span> <span class="p">=</span>

                  <span class="n">train_time</span><span class="p">:</span> <span class="mf">6.5180</span>
                   <span class="n">test_time</span><span class="p">:</span> <span class="mf">0.1000</span>
              <span class="n">train_accuracy</span><span class="p">:</span> <span class="mf">0.9627</span>
               <span class="n">test_accuracy</span><span class="p">:</span> <span class="mf">0.8342</span>
                <span class="n">time_network</span><span class="p">:</span> <span class="mf">11.7311</span>
    <span class="n">time_transform_test_data</span><span class="p">:</span> <span class="mf">10.9387</span>
</pre></div>
</div>
<p>效果提高了好多, 有木有！</p>
</div>
<div class="section" id="id31">
<h5>本人实现代码结果<a class="headerlink" href="#id31" title="永久链接至标题">¶</a></h5>
<p>重写的代码支持多通道图像, 输入为<span class="math">\(H-W-N-C\)</span>的矩阵, 其中<span class="math">\(C\)</span>为图像通道数.</p>
<p><strong>以下图片本人原创</strong> 实现了两种处理方式, 一是“sequential”模式, 如下：
<img alt="多通道图像处理示意图——sequential" src="../../../_images/20160312174915472.png" /></p>
<p>二是“parallel”模式, 如下： <img alt="多通道图像处理示意图——parallel" src="../../../_images/20160312175341467.png" /></p>
<p><a class="reference external" href="https://github.com/ExtremeLearningMachines/ELM-LRF">论文中用的</a>代码（这个应该是文章用的）, 采用的是sequential模型, 且没有直接采用卷积函数计算, 而是将卷积计算转化为矩阵乘积计算<span class="math">\(\bm WX\)</span>.
<img alt="卷积运算" src="../../../_images/20160312175946393.png" /></p>
<p>采用parallel模型, 参数与上述第一组一致, 并使<span class="math">\(C\)</span>取不同的值, 即：<span class="math">\(C = [0.001 0.01 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1]\)</span>, 结果如下：</p>
<p><strong>特征图数1：</strong></p>
<div class="highlight-matlab notranslate"><div class="highlight"><pre><span class="o">&gt;&gt;</span> <span class="n">pack</span>
<span class="o">&gt;&gt;</span> <span class="n">demo_elmlrf_NORB</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.001000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.141934</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">9.234375</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.257778</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.703125</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.010000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.074239</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">9.015625</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.208066</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.718750</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.100000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.042140</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">8.906250</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.216049</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.656250</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.200000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.035021</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">8.875000</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.220206</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.593750</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.300000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.031193</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">8.906250</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.223580</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.687500</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.400000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.029342</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">8.812500</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.226626</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.593750</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.500000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.027572</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">8.953125</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.228354</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.812500</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.600000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.026667</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">8.953125</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.230206</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.625000</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.700000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.026420</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">8.812500</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.231811</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.687500</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.800000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.025926</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">8.875000</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.233539</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.734375</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.900000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.025226</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">8.750000</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.234733</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.656250</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">1.000000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.024609</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">8.921875</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.236091</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">3.718750</span><span class="n">s</span>
</pre></div>
</div>
<p><strong>特征图数3：</strong></p>
<div class="highlight-matlab notranslate"><div class="highlight"><pre><span class="o">&gt;&gt;</span> <span class="n">demo_elmlrf_NORB</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.001000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.027284</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">61.468750</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.114856</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">14.625000</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.010000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.008272</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">64.171875</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.088724</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">13.921875</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.100000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.001564</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">61.515625</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.104033</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">13.281250</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.200000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.001070</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">60.546875</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.111111</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">12.625000</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.300000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.000947</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">58.468750</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.116831</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">12.765625</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.400000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.000741</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">56.328125</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.121152</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">12.281250</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.500000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.000700</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">56.671875</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.123498</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">12.765625</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.600000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.000658</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">61.468750</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.125021</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">13.328125</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.700000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.000617</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">58.515625</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.126584</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">12.828125</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.800000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.000576</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">59.359375</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.127984</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">12.796875</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">0.900000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.000535</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">60.296875</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.129136</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">12.156250</span><span class="n">s</span>

<span class="n">With</span> <span class="n">C</span> <span class="p">=</span> <span class="mf">1.000000</span>
<span class="o">-----------------------------------------</span>
<span class="n">Training</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.000494</span>
<span class="n">Training</span> <span class="n">Time</span><span class="p">:</span><span class="mf">62.718750</span><span class="n">s</span>

<span class="n">Testing</span> <span class="n">error</span><span class="p">:</span> <span class="mf">0.130082</span>
<span class="n">Testing</span> <span class="n">Time</span><span class="p">:</span><span class="mf">12.750000</span><span class="n">s</span>
</pre></div>
</div>
<p>根据实验结果, 可知：</p>
<ul class="simple">
<li><p>相同参数下, 本人实现的程序比文中略高（精确度）；</p></li>
<li><p>相同参数下, 本人实现的程比论文程序更序耗时些, 有待优化, 但容易扩展.</p></li>
</ul>
<p><strong>特征图展示：</strong></p>
<p>下面分别贴出NORB数据集前100幅图像的：原图、卷积操作后的特征图、均方根池化后的特征图. 可见隐藏层学习到了数据的特征.</p>
<p>NORB数据集前100幅图像: <img alt="NORB数据集前100幅图像——原图" src="../../../_images/20160311220420363.png" /></p>
<p>NORB数据集前100幅图像, 卷积后的特征图：
<img alt="NORB数据集前100幅图像——卷积后的特征图" src="../../../_images/20160311220603023.png" /></p>
<p>NORB数据集前100幅图像, 池化后的特征图：
<img alt="NORB数据集前100幅图像——池化后的特征图" src="../../../_images/20160311220640337.png" /></p>
</div>
</div>
</div>
</div>
<div class="section" id="id32">
<h2><span class="section-number">6.2.11. </span>参考文献<a class="headerlink" href="#id32" title="永久链接至标题">¶</a></h2>
<dl class="footnote brackets">
<dt class="label" id="id33"><span class="brackets"><a class="fn-backref" href="#id3">1</a></span></dt>
<dd><p>Huang G, Bai Z, Kasun L, et al. Local Receptive Fields Based Extreme
Learning Machine[J]. Computational Intelligence Magazine IEEE, 2015,
10(2):18 - 29.</p>
</dd>
<dt class="label" id="id34"><span class="brackets"><a class="fn-backref" href="#id4">2</a></span></dt>
<dd><p>Huang G B, Zhu Q Y, Siew C K. Extreme learning machine: a new
learning scheme of feedforward neural networks[J]. Proc.int.joint
Conf.neural Netw, 2004, 2:985–990.</p>
</dd>
<dt class="label" id="id35"><span class="brackets"><a class="fn-backref" href="#id9">3</a></span></dt>
<dd><p>Huang G B. Universal approximation using incremental constructive
feedforward networks with random hidden nodes.[J]. IEEE Transactions
on Neural Networks, 2006, 17(4):879 - 892.</p>
</dd>
<dt class="label" id="id36"><span class="brackets"><a class="fn-backref" href="#id10">4</a></span></dt>
<dd><p>Huang G B, Chen L, Huang G B, et al. Convex incremental extreme
learning machine[J]. Neurocomputing, 2007, 70:3056–3062.</p>
</dd>
<dt class="label" id="id37"><span class="brackets"><a class="fn-backref" href="#id11">5</a></span></dt>
<dd><p>Huang G B, Chen L. Enhanced random search based incremental extreme
learning machine[J]. Neurocomputing, 2008, 71(16-18):3460–3468.</p>
</dd>
</dl>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="FuzzyELM.html" class="btn btn-neutral float-right" title="6.3. 模糊极速学习机" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="ELM.html" class="btn btn-neutral" title="6.1. 经典极速学习机" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017-2019，刘志，西安电子科技大学，智能感知与图像理解教育部重点实验室.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> and ❤️  using a custom <a href="https://github.com/LinxiFan/Stanford-theme">theme</a> based on <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'0.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/language_data.js"></script>
      <script type="text/javascript" src="../../../_static/proof.js"></script>
      <script type="text/javascript" src="../../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script>
      <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script>
      <script type="text/javascript" src="../../../_static/katex_autorenderer.js"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>